{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e166dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import transformer_lens\n",
    "torch.set_default_device(\"cuda\")\n",
    "import seaborn as sns\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import pearsonr\n",
    "from enum import Enum\n",
    "from src.utils import get_w_vo, rearrange_heads_by_layer, top_k_indices, get_k, load_dataset, get_topm_relation_heads\n",
    "from src.maps import MAPS\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b72ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = r\"gpt2-xl\"\n",
    "model_family_name = \"gpt2\"\n",
    "model = transformer_lens.HookedTransformer.from_pretrained_no_processing(model_name, device_map=\"auto\")\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.eval()\n",
    "state_dict = model.state_dict()\n",
    "cfg = model.cfg\n",
    "is_gqa = cfg.n_key_value_heads != None\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_gpus = torch.cuda.device_count()\n",
    "last_device = torch.device(f\"cuda:{num_gpus-1}\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3668bb5",
   "metadata": {},
   "source": [
    "Predefined Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab49504",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_name = \"country_to_capital_wikidata\"\n",
    "k = get_k(model_name, relation_name)\n",
    "dataset = load_dataset(relation_name)\n",
    "apply_first_mlp = True\n",
    "maps = MAPS(model, tokenizer)\n",
    "relation_scores, suppression_relation_scores = maps.calc_relation_scores(\n",
    "    dataset,\n",
    "    apply_first_mlp,\n",
    "    k)\n",
    "sns.heatmap(relation_scores.T,vmin=0,vmax=1)\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"Head\")\n",
    "plt.title(f\"Relation scores\\n{relation_name}\\n{model_name}\\nk={k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a76e86c",
   "metadata": {},
   "source": [
    "Static vs dynamic relation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_name = \"country_to_capital_wikidata\"\n",
    "k = get_k(model_name, relation_name)\n",
    "dataset = load_dataset(relation_name)\n",
    "apply_first_mlp = True\n",
    "template=\"This is a document about <X>\"\n",
    "maps = MAPS(model, tokenizer)\n",
    "relation_scores, suppression_relation_scores = maps.calc_relation_scores(\n",
    "    dataset,\n",
    "    apply_first_mlp,\n",
    "    k)\n",
    "dynamic_results = maps.calc_dynamic_relation_scores(dataset, template, k)\n",
    "sns.scatterplot(x=relation_scores.flatten(),y=dynamic_results[\"wo_context_dynamic_relation_scores\"].flatten())\n",
    "corr,pval = pearsonr(relation_scores.flatten(),dynamic_results[\"wo_context_dynamic_relation_scores\"].flatten())\n",
    "plt.title(f\"Static vs Dynamic relation scores\\ntemplate={template}\\nPearson corr={corr:.2f}, pval={pval:.1e}\\nmodel={model_name}\\nw_context=False\")\n",
    "plt.xlabel(\"Relation score\")\n",
    "plt.ylabel(\"Dynamic relation score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202fe6f6",
   "metadata": {},
   "source": [
    "Causal Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e9cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_m_random_heads(m, heads_to_exclude, cfg):\n",
    "    heads_to_exclude_indexed = [layer*cfg.n_heads + head for (layer,head) in heads_to_exclude]\n",
    "    all_heads = [ix for ix in range(cfg.n_layers*cfg.n_heads)]\n",
    "    available_heads = list(set(all_heads) - set(heads_to_exclude_indexed))\n",
    "    sampled_heads_indexed = np.random.choice(available_heads, size=m, replace=False)\n",
    "    sampled_heads = [(ix // cfg.n_heads, ix % cfg.n_heads) for ix in sampled_heads_indexed]\n",
    "    return sampled_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b61da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "relation_name = \"name_copying\"\n",
    "template = \" John-> John; Donna-> Donna; <X>->\"\n",
    "dataset = load_dataset(relation_name)\n",
    "apply_first_mlp = True\n",
    "m_heads=150\n",
    "maps = MAPS(model, tokenizer)\n",
    "topm_relation_heads = get_topm_relation_heads(m_heads, maps, dataset, apply_first_mlp, get_k(model_name, relation_name), only_nonzero=True)\n",
    "accuracies = maps.calc_causal_effects(dataset, template, topm_relation_heads)\n",
    "control_relation_name = \"general_copying_english_500\"\n",
    "control_template = \" walk-> walk; cat-> cat; water-> water; <X>->\"\n",
    "control_dataset = load_dataset(control_relation_name)\n",
    "control_accuracies = maps.calc_causal_effects(control_dataset, control_template, topm_relation_heads)\n",
    "random_heads = sample_m_random_heads(m_heads, topm_relation_heads, cfg)\n",
    "random_accuracies = maps.calc_causal_effects(dataset, template, random_heads)\n",
    "sns.lineplot(accuracies,label=\"Main task, ablating relation heads\")\n",
    "sns.lineplot(control_accuracies,label=\"Control task (Copying), ablating relation heads\")\n",
    "sns.lineplot(random_accuracies,label=\"Main task, ablating random heads\")\n",
    "plt.title(f\"MAPS causal experiment\\nrelation={relation_name}\\ntemplate={template}\\n{model_name}\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.yticks(np.arange(0,1.05,0.1))\n",
    "plt.xlabel(\"# heads ablated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
